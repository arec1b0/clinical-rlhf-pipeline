# Clinical RLHF Pipeline - Production Configuration
# Uses real medical LLMs with quantization and LoRA

model:
  # Model selection (see src/models/model_registry.py for options)
  # Options: biogpt, biomistral-7b, meditron-7b, openbiollm-8b, medalpaca-7b
  medical_llm: "biomistral-7b"
  
  # Set to false to use real models instead of mocks
  use_mock_models: false
  
  # Auto-select based on hardware (overrides medical_llm if true)
  auto_select_model: false
  
  # Device settings
  device: "auto"  # auto, cuda, cpu, mps
  
  # Maximum sequence length
  max_length: 2048

# Model loading configuration
model_loading:
  # Quantization (saves GPU memory)
  load_in_4bit: true
  load_in_8bit: false
  
  # BitsAndBytes 4-bit config
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  
  # Flash Attention (faster on Ampere+ GPUs)
  use_flash_attention: true
  
  # LoRA fine-tuning config
  use_lora: true
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  
  # Memory optimization
  gradient_checkpointing: true
  
  # Share base model between policy and value (saves ~50% memory)
  share_value_base: false
  
  # HuggingFace cache directory (optional)
  cache_dir: null

reward_weights:
  # Multi-objective reward weights (must sum to 1.0)
  uncertainty_quantification: 0.25
  guideline_adherence: 0.30
  patient_safety: 0.35
  response_coherence: 0.10

uncertainty:
  mc_dropout_samples: 10
  temperature_scaling: true
  confidence_threshold: 0.7
  overconfidence_penalty: 2.0

safety:
  red_flag_symptoms:
    - "chest pain"
    - "difficulty breathing"
    - "sudden severe headache"
    - "loss of consciousness"
    - "signs of stroke"
    - "severe allergic reaction"
    - "suicidal ideation"
  
  contraindications_db: "data/contraindications.json"
  hard_safety_threshold: 0.3
  soft_safety_threshold: 0.6
  dosage_validation: true
  dosage_db: "data/medication_dosages.json"

guidelines:
  sources:
    - name: "CDC"
      weight: 0.3
    - name: "WHO"
      weight: 0.25
    - name: "NICE"
      weight: 0.25
    - name: "UpToDate"
      weight: 0.2
  
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  min_adherence_score: 0.5

training:
  ppo:
    learning_rate: 1.0e-5  # Lower LR for real models
    batch_size: 4  # Smaller batch for memory
    mini_batch_size: 2
    ppo_epochs: 4
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_vf: 0.2
    vf_coef: 0.5
    max_grad_norm: 0.5
    target_kl: 0.01
  
  # Training schedule
  total_steps: 10000
  eval_frequency: 500
  save_frequency: 1000
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 5
    min_delta: 0.001
  
  # Safety constraints
  max_unsafe_ratio: 0.05

observability:
  mlflow:
    tracking_uri: "http://localhost:5000"
    experiment_name: "clinical-rlhf-production"
    
  prometheus:
    enabled: true
    port: 8000
    
  logging:
    level: "INFO"
    format: "json"
    
  alerts:
    safety_violation_threshold: 0.1
    reward_degradation_threshold: 0.15

data:
  feedback_collection:
    min_experts_per_sample: 3
    agreement_threshold: 0.7
    
  quality_checks:
    - "duplicate_detection"
    - "label_consistency"
    - "temporal_leakage"
